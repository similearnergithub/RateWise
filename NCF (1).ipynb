{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpG1l9ilsSlw",
        "outputId": "10166545-f121-4c06-cf47-993a092f7aac"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 0.9351 - val_loss: 0.7863\n",
            "Epoch 2/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3ms/step - loss: 0.7274 - val_loss: 0.7320\n",
            "Epoch 3/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - loss: 0.6862 - val_loss: 0.7256\n",
            "Epoch 4/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3ms/step - loss: 0.6562 - val_loss: 0.7194\n",
            "Epoch 5/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - loss: 0.6257 - val_loss: 0.7196\n",
            "Epoch 6/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - loss: 0.5977 - val_loss: 0.7166\n",
            "Epoch 7/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3ms/step - loss: 0.5730 - val_loss: 0.7242\n",
            "Epoch 8/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 0.5509 - val_loss: 0.7312\n",
            "Epoch 9/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - loss: 0.5320 - val_loss: 0.7397\n",
            "Epoch 10/10\n",
            "\u001b[1m32643/32643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - loss: 0.5120 - val_loss: 0.7404\n",
            "\u001b[1m20402/20402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step\n",
            "NCF RMSE: 0.8615322503915215\n",
            "NCF MAE: 0.6514316748538242\n"
          ]
        }
      ],
      "source": [
        "# NCF Model for Collaborative Filtering\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "\n",
        "# Load the ratings data\n",
        "df = pd.read_csv('/content/ratings.csv')\n",
        "\n",
        "# Prepare user and movie IDs\n",
        "user_ids = df['userId'].values\n",
        "movie_ids = df['movieId'].values\n",
        "ratings = df['rating'].values\n",
        "\n",
        "# Split data into training and test sets\n",
        "user_ids_train, user_ids_test, movie_ids_train, movie_ids_test, ratings_train, ratings_test = train_test_split(\n",
        "    user_ids, movie_ids, ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Neural Collaborative Filtering (NCF) Model\n",
        "num_users = df['userId'].nunique()\n",
        "num_movies = df['movieId'].nunique()\n",
        "\n",
        "# Input layers\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "\n",
        "# Embedding layers\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=50, input_length=1)(user_input)\n",
        "movie_embedding = Embedding(input_dim=num_movies, output_dim=50, input_length=1)(movie_input)\n",
        "\n",
        "# Flatten the embeddings\n",
        "user_flat = Flatten()(user_embedding)\n",
        "movie_flat = Flatten()(movie_embedding)\n",
        "\n",
        "# Concatenate user and movie embeddings\n",
        "concat = Concatenate()([user_flat, movie_flat])\n",
        "\n",
        "# Dense layers\n",
        "dense1 = Dense(128, activation='relu')(concat)\n",
        "dense2 = Dense(64, activation='relu')(dense1)\n",
        "dense3 = Dense(32, activation='relu')(dense2)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1)(dense3)\n",
        "\n",
        "# Create the model\n",
        "ncf_model = Model([user_input, movie_input], output)\n",
        "ncf_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the NCF model\n",
        "ncf_model.fit([user_ids_train, movie_ids_train], ratings_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the NCF model\n",
        "ratings_pred = ncf_model.predict([user_ids_test, movie_ids_test])\n",
        "rmse = np.sqrt(mean_squared_error(ratings_test, ratings_pred))\n",
        "mae = mean_absolute_error(ratings_test, ratings_pred)\n",
        "\n",
        "print(f\"NCF RMSE: {rmse}\")\n",
        "print(f\"NCF MAE: {mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "\n",
        "# Load the ratings data\n",
        "df = pd.read_csv('/content/ratings.csv')\n",
        "\n",
        "# Prepare user and movie IDs\n",
        "user_ids = df['userId'].values\n",
        "movie_ids = df['movieId'].values\n",
        "ratings = df['rating'].values\n",
        "\n",
        "# Split data into training and test sets\n",
        "user_ids_train, user_ids_test, movie_ids_train, movie_ids_test, ratings_train, ratings_test = train_test_split(\n",
        "    user_ids, movie_ids, ratings, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define the Neural Collaborative Filtering (NCF) Model\n",
        "num_users = df['userId'].nunique()\n",
        "num_movies = df['movieId'].nunique()\n",
        "\n",
        "# Input layers\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "\n",
        "# Embedding layers\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=50, input_length=1)(user_input)\n",
        "movie_embedding = Embedding(input_dim=num_movies, output_dim=50, input_length=1)(movie_input)\n",
        "\n",
        "# Flatten the embeddings\n",
        "user_flat = Flatten()(user_embedding)\n",
        "movie_flat = Flatten()(movie_embedding)\n",
        "\n",
        "# Concatenate user and movie embeddings\n",
        "concat = Concatenate()([user_flat, movie_flat])\n",
        "\n",
        "# Dense layers\n",
        "dense1 = Dense(128, activation='relu')(concat)\n",
        "dense2 = Dense(64, activation='relu')(dense1)\n",
        "dense3 = Dense(32, activation='relu')(dense2)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1)(dense3)\n",
        "\n",
        "# Create the model\n",
        "ncf_model = Model([user_input, movie_input], output)\n",
        "ncf_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the NCF model\n",
        "ncf_model.fit([user_ids_train, movie_ids_train], ratings_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the NCF model\n",
        "ratings_pred = ncf_model.predict([user_ids_test, movie_ids_test])\n",
        "rmse = np.sqrt(mean_squared_error(ratings_test, ratings_pred))\n",
        "mae = mean_absolute_error(ratings_test, ratings_pred)\n",
        "r2 = r2_score(ratings_test, ratings_pred)\n",
        "\n",
        "print(f\"NCF RMSE: {rmse}\")\n",
        "print(f\"NCF MAE: {mae}\")\n",
        "print(f\"NCF R²: {r2}\")\n"
      ],
      "metadata": {
        "id": "s8mkmhfxIcXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8edd97-2821-44c7-d003-9b9153d72153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 1.1419 - val_loss: 0.7540\n",
            "Epoch 2/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.7253 - val_loss: 0.7322\n",
            "Epoch 3/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 0.6839 - val_loss: 0.7281\n",
            "Epoch 4/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.6414 - val_loss: 0.7245\n",
            "Epoch 5/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.5989 - val_loss: 0.7313\n",
            "Epoch 6/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.5578 - val_loss: 0.7496\n",
            "Epoch 7/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 0.5210 - val_loss: 0.7557\n",
            "Epoch 8/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.4877 - val_loss: 0.7732\n",
            "Epoch 9/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.4632 - val_loss: 0.7898\n",
            "Epoch 10/10\n",
            "\u001b[1m6978/6978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.4366 - val_loss: 0.8070\n",
            "\u001b[1m4362/4362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
            "NCF RMSE: 0.8987675563389571\n",
            "NCF MAE: 0.6776490966246219\n",
            "NCF R²: 0.24544432662245896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7JMixwDp8Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JHGpj0xvyjy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}